name: Train-MLAgents-Simple

on:
  workflow_dispatch:
    inputs:
      gdrive_file_id:
        description: "Google Drive file id Ù„Ù…Ù„Ù Ø§Ù„Ù€ ZIP Ø§Ù„Ø®Ø§Øµ Ø¨Ø¨Ù†Ø§Ø¡ Linux"
        required: true
        default: "1wOrwyYQHbaiK_XFouEutm0t88RrlRQ5-"
      run_id:
        description: "ÙˆØ³Ù… ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"
        required: true
        default: "drone_run_001"
      time_scale:
        description: "Unity time scale (ÙƒÙ„Ù…Ø§ Ø²Ø§Ø¯ Ø£Ø³Ø±Ø¹)"
        required: true
        default: "20"

jobs:
  train:
    runs-on: ubuntu-latest
    timeout-minutes: 360

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python 3.8.18
        uses: actions/setup-python@v5
        with:
          python-version: "3.8.18"

      - name: Install ML-Agents (simple approach)
        run: |
          python -m pip install -U pip
          # Install system dependencies
          sudo apt-get update
          sudo apt-get install -y xvfb
          
          # Install ML-Agents 0.27.0 which is stable and well-tested
          pip install torch==1.11.0 torchvision==0.12.0
          pip install mlagents==0.27.0
          pip install gdown

      - name: Download and extract Unity build
        run: |
          mkdir -p env_zip
          gdown --id "${{ github.event.inputs.gdrive_file_id }}" -O env_zip/build.zip
          
          mkdir -p env
          unzip -q env_zip/build.zip -d ./env
          
          # Find executable
          EXE=$(find ./env -type f -iname "*.x86_64" ! -path "*/__MACOSX/*" | head -n1)
          if [ -z "$EXE" ]; then
            echo "âŒ No executable found!"
            find ./env -type f | head -10
            exit 1
          fi
          
          chmod +x "$EXE"
          echo "EXE_PATH=$EXE" >> $GITHUB_ENV
          echo "âœ… Found executable: $EXE"

      - name: Test Unity environment
        env:
          DISPLAY: :99
        run: |
          # Start virtual display
          Xvfb :99 -screen 0 1024x768x24 &
          sleep 2
          
          # Quick environment test
          python -c "
          import os
          from mlagents_envs.environment import UnityEnvironment
          
          print('Testing Unity environment...')
          env = UnityEnvironment(file_name='$EXE_PATH', no_graphics=True, timeout_wait=60)
          env.reset()
          behaviors = list(env.behavior_specs.keys())
          print(f'âœ… Found behaviors: {behaviors}')
          env.close()
          "

      - name: Create training config
        run: |
          cat > train_config.yaml << 'EOF'
          behaviors:
            DroneInterceptor:
              trainer_type: ppo
              hyperparameters:
                batch_size: 1024
                buffer_size: 10240
                learning_rate: 3.0e-4
                beta: 5.0e-3
                epsilon: 0.2
                lambd: 0.95
                num_epoch: 3
                learning_rate_schedule: constant
              network_settings:
                normalize: true
                hidden_units: 128
                num_layers: 2
              reward_signals:
                extrinsic:
                  gamma: 0.99
                  strength: 1.0
              max_steps: 1000000
              time_horizon: 64
              summary_freq: 10000
          EOF
          
          echo "âœ… Training config created"
          cat train_config.yaml

      - name: Run ML-Agents training
        env:
          DISPLAY: :99
        run: |
          # Ensure display is running
          pgrep Xvfb || Xvfb :99 -screen 0 1024x768x24 &
          sleep 2
          
          echo "ðŸš€ Starting training..."
          echo "Environment: $EXE_PATH"
          echo "Run ID: ${{ github.event.inputs.run_id }}"
          
          # Run training with timeout
          timeout 330m mlagents-learn train_config.yaml \
            --env="$EXE_PATH" \
            --run-id="${{ github.event.inputs.run_id }}" \
            --no-graphics \
            --time-scale="${{ github.event.inputs.time_scale }}" \
            --force || {
            
            EXIT_CODE=$?
            echo "Training ended with code: $EXIT_CODE"
            
            # Check if we have results anyway
            if [ -d "results/${{ github.event.inputs.run_id }}" ]; then
              echo "âœ… Results directory exists"
              find "results/${{ github.event.inputs.run_id }}" -name "*.onnx" -o -name "*.nn" && {
                echo "âœ… Model files found - training succeeded!"
                exit 0
              }
            fi
            
            echo "âŒ Training failed - no results"
            exit 1
          }
          
          echo "âœ… Training completed successfully!"

      - name: Show results
        if: always()
        run: |
          if [ -d "results/${{ github.event.inputs.run_id }}" ]; then
            echo "=== Training Results ==="
            find "results/${{ github.event.inputs.run_id }}" -type f | head -20
            echo ""
            echo "=== Model Files ==="
            find "results/${{ github.event.inputs.run_id }}" -name "*.onnx" -o -name "*.nn" | while read f; do
              echo "ðŸ“„ $f ($(du -h "$f" | cut -f1))"
            done
          else
            echo "âŒ No results found"
          fi

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: training-results-${{ github.event.inputs.run_id }}
          path: results

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: training-logs-${{ github.event.inputs.run_id }}
          path: |
            *.log
            results/*/run_logs/
        continue-on-error: true
