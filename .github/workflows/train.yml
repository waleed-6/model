name: Train-MLAgents-CPU-Enhanced-Debug

on:
  workflow_dispatch:
    inputs:
      gdrive_file_id:
        description: "Google Drive file id لملف الـ ZIP الخاص ببناء Linux"
        required: true
        default: "1wOrwyYQHbaiK_XFouEutm0t88RrlRQ5-"
      yaml_path:
        description: "مسار YAML (اختياري). اتركه فاضي لاكتشاف تلقائي"
        required: false
        default: ""
      run_id:
        description: "وسم تشغيل التدريب"
        required: true
        default: "drone_run_001"
      time_scale:
        description: "Unity time scale (كلما زاد أسرع)"
        required: true
        default: "20"

jobs:
  train:
    runs-on: ubuntu-latest
    timeout-minutes: 360
    env:
      PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION: python

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Show repo contents (debug)
        run: |
          echo "PWD: $(pwd)"
          echo "Branch: ${{ github.ref }}"
          echo "Root listing:"
          ls -la
          echo "Search for interceptor yaml candidates:"
          find . -maxdepth 5 -iname "interceptor*.yml*" -print || true

      - name: Resolve YAML path
        id: resolveyaml
        run: |
          INP="${{ github.event.inputs.yaml_path }}"
          if [ -n "$INP" ] && [ -f "$INP" ]; then
            echo "yaml_path=$INP" >> $GITHUB_OUTPUT
            echo "Using provided YAML: $INP"
            exit 0
          fi

          for p in \
            interceptor_pro.yaml \
            interceptor_pro.yml \
            config/interceptor_pro.yaml \
            config/interceptor_pro.yml \
            Assets/config/interceptor_pro.yaml \
            Assets/config/interceptor_pro.yml
          do
            if [ -f "$p" ]; then
              echo "yaml_path=$p" >> $GITHUB_OUTPUT
              echo "Auto-detected YAML at $p"
              exit 0
            fi
          done

          CAND=$(find . -maxdepth 5 -iname "interceptor*.yml*" | head -n1)
          if [ -n "$CAND" ] && [ -f "$CAND" ]; then
            echo "yaml_path=$CAND" >> $GITHUB_OUTPUT
            echo "Found YAML at $CAND"
            exit 0
          fi

          echo "Could not find interceptor_pro.yaml/.yml. Commit it أو حدد 'yaml_path' عند تشغيل الـ workflow."
          exit 1

      - name: Set up Python 3.10.8 (compatible with mlagents 0.30.0)
        uses: actions/setup-python@v5
        with:
          python-version: "3.10.8"

      - name: Install trainer + tools (with compatibility fixes)
        run: |
          python -m pip install -U pip
          # Install minimal graphics dependencies for headless Unity
          sudo apt-get update
          sudo apt-get install -y xvfb libopengl0 libglu1-mesa libxrandr2 libxinerama1 libxcursor1 || echo "Some packages failed, continuing..."
          # Install core dependencies first to avoid conflicts
          pip install "protobuf==3.20.3"
          pip install "six"
          pip install "setuptools<70.0.0"
          # Install specific compatible versions
          pip install "numpy<1.24.0"
          pip install "torch==1.13.1"
          pip install "tensorboard==2.11.2"
          # Install ML-Agents compatible with Unity ML-Agents 2.0.1
          # Unity 2.0.1 is compatible with Python mlagents ~0.28.0-0.30.0
          pip install "mlagents==0.28.0" "mlagents_envs==0.28.0"
          pip install gdown

      - name: Download Linux build from Google Drive
        run: |
          mkdir -p env_zip
          gdown --id "${{ github.event.inputs.gdrive_file_id }}" -O env_zip/build.zip
          ls -lh env_zip

      - name: Unzip build and make executable (robust)
        id: unzipbuild
        run: |
          mkdir -p env
          unzip -q env_zip/build.zip -d ./env || { echo "Unzip failed"; exit 1; }

          echo "Top-level after unzip:"
          find ./env -maxdepth 3 -print

          # امسك أول ملف تنفيذي لينُكس .x86_64 وتجاهل __MACOSX
          EXE=$(find ./env -type f -iname "*.x86_64" ! -path "*/__MACOSX/*" | head -n1)

          if [ -z "$EXE" ]; then
            echo "No .x86_64 executable found. Full tree for debug:"
            find ./env -maxdepth 5 -print
            exit 1
          fi

          chmod +x "$EXE"
          echo "exe_path=$EXE" >> $GITHUB_OUTPUT
          echo "Using executable: $EXE"
          
          # Check executable details
          echo "=== Executable Info ==="
          ls -la "$EXE"
          file "$EXE"
          ldd "$EXE" | head -10 || echo "ldd failed"

      - name: Create enhanced probe script
        run: |
          cat > enhanced_probe.py << 'ENHANCED_PROBE'
          import os
          import sys
          import time
          import signal
          from mlagents_envs.environment import UnityEnvironment
          from mlagents_envs.exception import UnityWorkerInUseException

          def signal_handler(signum, frame):
              print(f"[Probe] Received signal {signum}, exiting...")
              sys.exit(1)

          signal.signal(signal.SIGTERM, signal_handler)
          signal.signal(signal.SIGINT, signal_handler)

          env_path = os.environ.get("ENV_PATH")
          print(f"[Probe] Testing environment: {env_path}")
          print(f"[Probe] File exists: {os.path.exists(env_path)}")
          print(f"[Probe] File executable: {os.access(env_path, os.X_OK)}")

          try:
              print("[Probe] Creating Unity environment...")
              env = UnityEnvironment(
                  file_name=env_path, 
                  no_graphics=True, 
                  timeout_wait=300,  # Increased timeout
                  base_port=5005,
                  seed=42,
                  side_channels=[],
                  log_folder="./unity_logs"
              )
              
              print("[Probe] Environment created successfully!")
              print("[Probe] Resetting environment...")
              env.reset()
              
              names = list(env.behavior_specs.keys())
              print(f"[Probe] Found {len(names)} behaviors: {names}")
              
              for name in names:
                  spec = env.behavior_specs[name]
                  if spec.action_spec.is_discrete():
                      action_info = f"discrete branches: {spec.action_spec.discrete_branch_sizes}"
                  else:
                      action_info = f"continuous size: {spec.action_spec.continuous_size}"
                  
                  obs_shapes = [obs.shape for obs in spec.observation_specs]
                  print(f"[Probe] {name}:")
                  print(f"  - Observations: {obs_shapes}")
                  print(f"  - Actions: {action_info}")
                  print(f"  - Max agents: {spec.max_agent_steps}")
              
              # Test a few steps
              print("[Probe] Testing environment steps...")
              for i in range(3):
                  decision_steps, terminal_steps = env.get_steps(names[0])
                  print(f"[Probe] Step {i}: {len(decision_steps)} decision agents, {len(terminal_steps)} terminal agents")
                  if len(decision_steps) > 0:
                      # Send random actions
                      if spec.action_spec.is_discrete():
                          actions = env.behavior_specs[names[0]].action_spec.random_action(len(decision_steps))
                      else:
                          actions = env.behavior_specs[names[0]].action_spec.random_action(len(decision_steps))
                      env.set_actions(names[0], actions)
                      env.step()
                  time.sleep(0.1)
              
              print("[Probe] Closing environment...")
              env.close()
              print("[Probe] ✅ Environment test completed successfully!")
              
          except UnityWorkerInUseException as e:
              print(f"[Probe] ❌ Port conflict: {e}")
              sys.exit(1)
          except Exception as e:
              print(f"[Probe] ❌ Environment error: {type(e).__name__}: {e}")
              import traceback
              traceback.print_exc()
              sys.exit(1)
          ENHANCED_PROBE

      - name: Test environment with enhanced diagnostics
        env:
          ENV_PATH: ${{ steps.unzipbuild.outputs.exe_path }}
          DISPLAY: :99
        run: |
          # Start virtual display
          Xvfb :99 -screen 0 1024x768x24 &
          sleep 3
          
          echo "=== System Resources ==="
          free -h
          df -h
          echo "=== Graphics Libraries ==="
          ldconfig -p | grep -i gl || echo "No GL libraries found"
          
          echo "=== Testing Environment ==="
          mkdir -p unity_logs
          timeout 180 python enhanced_probe.py || {
            echo "=== Environment test failed, checking Unity logs ==="
            find . -name "*.log" -exec echo "=== {} ===" \; -exec cat {} \; || echo "No log files found"
            ls -la unity_logs/ || echo "No unity_logs directory"
            exit 1
          }

      - name: Validate YAML configuration
        run: |
          echo "=== YAML Configuration Check ==="
          cat "${{ steps.resolveyaml.outputs.yaml_path }}"
          echo ""
          echo "=== Python YAML Parse Test ==="
          python -c "
          import yaml
          with open('${{ steps.resolveyaml.outputs.yaml_path }}', 'r') as f:
              config = yaml.safe_load(f)
          print('YAML parsed successfully')
          print('Behaviors found:', list(config.get('behaviors', {}).keys()))
          "

      - name: Train with enhanced logging
        env:
          ENV_PATH: ${{ steps.unzipbuild.outputs.exe_path }}
          DISPLAY: :99
          MLAGENTS_LOG_LEVEL: DEBUG
        run: |
          echo "YAML path resolved to: ${{ steps.resolveyaml.outputs.yaml_path }}"
          echo "ENV executable: ${ENV_PATH}"
          
          # Start virtual display if not running
          pgrep Xvfb || Xvfb :99 -screen 0 1024x768x24 &
          sleep 2
          
          # Create logs directory
          mkdir -p training_logs
          
          echo "=== Starting Training ==="
          echo "Command: mlagents-learn ${{ steps.resolveyaml.outputs.yaml_path }} --env=${ENV_PATH} --run-id=${{ github.event.inputs.run_id }} --no-graphics --time-scale=${{ github.event.inputs.time_scale }} --force --base-port=5005"
          
          # Run training with detailed logging
          timeout 340m mlagents-learn "${{ steps.resolveyaml.outputs.yaml_path }}" \
            --env="${ENV_PATH}" \
            --run-id="${{ github.event.inputs.run_id }}" \
            --no-graphics \
            --time-scale="${{ github.event.inputs.time_scale }}" \
            --force \
            --base-port=5005 2>&1 | tee training_logs/full_output.log || {
            
            TRAINING_EXIT_CODE=$?
            echo "=== Training Exit Code: $TRAINING_EXIT_CODE ==="
            
            echo "=== Checking Results ==="
            ls -la results/ 2>/dev/null || echo "No results directory"
            
            if [ -d "results/${{ github.event.inputs.run_id }}" ]; then
              echo "✅ Results directory exists"
              find "results/${{ github.event.inputs.run_id }}" -type f | head -10
              
              # Look for model files
              if find "results/${{ github.event.inputs.run_id }}" -name "*.onnx" -o -name "*.nn" | grep -q .; then
                echo "✅ Model files found - training may have completed"
                find "results/${{ github.event.inputs.run_id }}" -name "*.onnx" -o -name "*.nn"
              else
                echo "❌ No model files found"
              fi
            else
              echo "❌ No results directory found"
            fi
            
            echo "=== Unity Logs ==="
            find . -name "*.log" -newer training_logs -exec echo "=== {} ===" \; -exec tail -20 {} \; 2>/dev/null || echo "No recent Unity logs"
            
            # Don't exit with error if results exist
            if [ -d "results/${{ github.event.inputs.run_id }}" ] && find "results/${{ github.event.inputs.run_id }}" -name "*.onnx" -o -name "*.nn" | grep -q .; then
              echo "Training completed with model files despite timeout"
              exit 0
            else
              echo "Training failed - no usable results"
              exit 1
            fi
          }

      - name: Display training results
        if: always()
        run: |
          echo "=== Training Results Summary ==="
          if [ -d "results/${{ github.event.inputs.run_id }}" ]; then
            echo "✅ Training completed successfully!"
            echo "📁 Results directory structure:"
            find results/${{ github.event.inputs.run_id }} -type f | head -20
            echo ""
            echo "🧠 Model files generated:"
            find results/${{ github.event.inputs.run_id }} -name "*.onnx" -o -name "*.nn" | while read file; do
              echo "  📄 $file ($(du -h "$file" | cut -f1))"
            done
            echo ""
            echo "📊 Training stats:"
            find results/${{ github.event.inputs.run_id }} -name "*.csv" | head -3 | while read file; do
              echo "  📈 $file ($(wc -l < "$file") lines)"
            done
          else
            echo "❌ No training results found"
          fi

      - name: Upload training results
        uses: actions/upload-artifact@v4
        with:
          name: results-${{ github.event.inputs.run_id }}
          path: results

      - name: Upload comprehensive logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: logs-${{ github.event.inputs.run_id }}
          path: |
            *.log
            unity_logs/
            training_logs/
            results/*/run_logs/
        continue-on-error: true
